{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 8\n",
    "# Regresión lineal, multiple y logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Santiago Blasco Arnaiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comandos bash para la descarga, descompresión y creación de los ficheros requeridos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Las siguientes celdas no serán ejecutadas, para que se ejecuten han de cambiarse a celdas de código)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Descargamos los archivos desde la url\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00459/avila.zip'\n",
    "\n",
    "!wget $url"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Descomprimimos el archivo para obtener los dos que nos interesan\n",
    "zipFile = 'avila.zip'\n",
    "\n",
    "!unzip $zipFile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Añadimos la cabecera y juntamos ambos archivos en unos solo\n",
    "head = 'F1,F2,F3,F4,F5,F6,F7,F8,F9,F10,Class'\n",
    "dataset = 'dataset.txt'\n",
    "\n",
    "!echo $head | tee $dataset\n",
    "\n",
    "trFile = './avila/avila-tr.txt'\n",
    "tsFile = './avila/avila-ts.txt'\n",
    "!cat $trFile $tsFile >> $dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Aquí terminan las celdas que ejecutan comandos bash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = pd.read_csv('dataset.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.165620</td>\n",
       "      <td>0.320980</td>\n",
       "      <td>0.483299</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.273364</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>0.929823</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.159345</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130292</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.436060</td>\n",
       "      <td>1.465940</td>\n",
       "      <td>0.636203</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>-0.783147</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.439463</td>\n",
       "      <td>-0.081827</td>\n",
       "      <td>-0.888236</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>0.582939</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.583590</td>\n",
       "      <td>-0.721442</td>\n",
       "      <td>-0.307984</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>1.051693</td>\n",
       "      <td>0.594169</td>\n",
       "      <td>-0.533994</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229043</td>\n",
       "      <td>0.807926</td>\n",
       "      <td>-0.052442</td>\n",
       "      <td>0.082634</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.148790</td>\n",
       "      <td>0.635431</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>-0.086652</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20862</th>\n",
       "      <td>-0.128929</td>\n",
       "      <td>-0.040001</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.557894</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.930856</td>\n",
       "      <td>-0.044076</td>\n",
       "      <td>1.158458</td>\n",
       "      <td>2.277968</td>\n",
       "      <td>-0.699884</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20863</th>\n",
       "      <td>0.266074</td>\n",
       "      <td>0.556689</td>\n",
       "      <td>-0.020434</td>\n",
       "      <td>0.176624</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.515608</td>\n",
       "      <td>0.597681</td>\n",
       "      <td>0.178349</td>\n",
       "      <td>0.625350</td>\n",
       "      <td>-0.657245</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20864</th>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.580242</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>-0.016668</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.519109</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.985508</td>\n",
       "      <td>-0.403638</td>\n",
       "      <td>1.276301</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20865</th>\n",
       "      <td>0.080916</td>\n",
       "      <td>0.588093</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.930856</td>\n",
       "      <td>-0.270579</td>\n",
       "      <td>0.163807</td>\n",
       "      <td>-0.091823</td>\n",
       "      <td>-0.593329</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20866</th>\n",
       "      <td>0.377169</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.381439</td>\n",
       "      <td>0.292753</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-1.470679</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>-0.494919</td>\n",
       "      <td>-0.247731</td>\n",
       "      <td>-1.212974</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20867 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F1        F2        F3        F4        F5        F6        F7  \\\n",
       "0      0.266074 -0.165620  0.320980  0.483299  0.172340  0.273364  0.371178   \n",
       "1      0.130292  0.870736 -3.210528  0.062493  0.261718  1.436060  1.465940   \n",
       "2     -0.116585  0.069915  0.068476 -0.783147  0.261718  0.439463 -0.081827   \n",
       "3      0.031541  0.297600 -3.210528 -0.583590 -0.721442 -0.307984  0.710932   \n",
       "4      0.229043  0.807926 -0.052442  0.082634  0.261718  0.148790  0.635431   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "20862 -0.128929 -0.040001  0.057807  0.557894  0.261718 -0.930856 -0.044076   \n",
       "20863  0.266074  0.556689 -0.020434  0.176624  0.261718 -0.515608  0.597681   \n",
       "20864 -0.054866  0.580242  0.032912 -0.016668  0.261718  1.519109  0.371178   \n",
       "20865  0.080916  0.588093  0.015130  0.002250  0.261718 -0.930856 -0.270579   \n",
       "20866  0.377169  0.014957  0.381439  0.292753  0.261718 -1.470679 -0.006326   \n",
       "\n",
       "             F8        F9       F10 Class  \n",
       "0      0.929823  0.251173  0.159345     A  \n",
       "1      0.636203  0.282354  0.515587     A  \n",
       "2     -0.888236 -0.123005  0.582939     A  \n",
       "3      1.051693  0.594169 -0.533994     A  \n",
       "4      0.051062  0.032902 -0.086652     F  \n",
       "...         ...       ...       ...   ...  \n",
       "20862  1.158458  2.277968 -0.699884     X  \n",
       "20863  0.178349  0.625350 -0.657245     G  \n",
       "20864 -0.985508 -0.403638  1.276301     A  \n",
       "20865  0.163807 -0.091823 -0.593329     F  \n",
       "20866 -0.494919 -0.247731 -1.212974     H  \n",
       "\n",
       "[20867 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metemos el dataframe en un array para poder trabajar más comodamente\n",
    "data = np.asarray(dataRaw)\n",
    "\n",
    "#Separamos el conjunto en los valores de las etiquetas y de la clae\n",
    "XRaw,Y = data[:,:-1], data[:,-1]\n",
    "\n",
    "#Creamos el escalador y escalamos los datos\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(XRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20867, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarizamos los posibles valores de la clase\n",
    "binTarget = LabelBinarizer().fit(np.unique(Y)).transform(Y)\n",
    "binTarget.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13911, 10), (6956, 10), (13911, 12), (6956, 12))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separamos tanto los valores de las etiquetas como de la clase\n",
    "#en los conjuntos de train (2/3) y test (1/3)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,binTarget, test_size= 1/3, random_state=1, stratify=Y)\n",
    "\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el array en el que almacenaremos la predicción de cada clasificador\n",
    "Y_predict = np.zeros(Y_test.shape, dtype=float)\n",
    "\n",
    "#Necesitamos un clasificador para cada valor de la clase\n",
    "for i in range(Y_test.shape[1]):\n",
    "    \n",
    "    #Creamos el clasificador y lo ajustamos con los datos de entrenamiento de la clase que toca\n",
    "    regresion = LinearRegression().fit(X_train, Y_train[:,i])\n",
    "    \n",
    "    #Añadimos la predicción al array de predicciones\n",
    "    Y_predict[:,i] = regresion.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de aciertos obtenida con hold out utilizando regresión lineal de respuesta múltiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.4778608395629672\n"
     ]
    }
   ],
   "source": [
    "print(\"Tasa de aciertos =\", accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_predict, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión obtenida con hold out utilizando regresión lineal de respuesta múltiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      " [[2780    0    0    0    3   37    0    0   37    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    3    0    0    0]\n",
      " [  55    0    0    0    2    7    0    0    5    0    0    0]\n",
      " [ 220    0    0    0    5    2    0    0    8    0    0    0]\n",
      " [ 675    0    0    0   12   29    0    0   14    0    0    0]\n",
      " [1285    0    0    0    0    8    0    0   15    0    0    0]\n",
      " [ 289    0    0    0    1    6    0    0    2    0    0    0]\n",
      " [ 276    0    0    0    7   30    0    0   33    0    0    0]\n",
      " [  55    0    0    0    3   10    0    0  482    0    4    0]\n",
      " [  26    0    0    0    4    0    0    0    0    0    0    0]\n",
      " [ 211    0    0    0   12    0    0    0   83    0   42    0]\n",
      " [  37    0    0    0    5    1    0    0  131    0    4    0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMatriz de Confusión:\\n\", confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(Y_predict, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation 10 particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Número de particiones en que queremos dividir el dataset\n",
    "subsamples = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=subsamples, random_state=None, shuffle=False)\n",
    "#Variables para calcular la tasa de acierto media\n",
    "score = 0\n",
    "#Asignamos las particiones de train y test un total de 10 veces\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    #Dividimos en train y test según los índices que nos marca el iterador\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = binTarget[train_index], binTarget[test_index]\n",
    "    \n",
    "    #Creamos el array en el que almacenaremos la predicción de cada clasificador\n",
    "    Y_predict = np.zeros(Y_test.shape, dtype=float)\n",
    "    \n",
    "    #Necesitamos un clasificador para cada valor de la clase\n",
    "    for i in range(Y_test.shape[1]):\n",
    "        \n",
    "        #Creamos el clasificador y lo ajustamos con los datos de entrenamiento de la clase que toca\n",
    "        regresion = LinearRegression().fit(X_train, Y_train[:,i])\n",
    "        \n",
    "        #Añadimos la predicción al array de predicciones\n",
    "        Y_predict[:,i] = regresion.predict(X_test)\n",
    "    \n",
    "    #Sumamos todos los scores\n",
    "    score = score + accuracy_score(np.argmax(Y_test, axis=1), np.argmax(Y_predict, axis=1))\n",
    "\n",
    "#Para a continuación obtener el score medio\n",
    "score = score/subsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de aciertos obtenida con XV 10 particiones utilizando regresión lineal de respuesta múltiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.4814777688296402\n"
     ]
    }
   ],
   "source": [
    "print(\"Tasa de aciertos =\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos resultados son similares, no notamos una mejora significativa al variar los conjuntos de entrenamiento y test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13911, 10), (6956, 10), (13911,), (6956,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separamos tanto los valores de las etiquetas como de la clase\n",
    "#en los conjuntos de train (2/3) y test (1/3)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size= 1/3, random_state=1, stratify=Y)\n",
    "\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el clasificador\n",
    "#(El parámetro multi_class lo dejamos por defecto ya que \n",
    "#entonces toma el valor 'ovr' que lo ajusta a un problema binario por cada etiqueta de clase)\n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "#Ajustamos el clasificador con los datos de entrenamiento\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Predecimos con el clasificador que acabamos de crear y ajsutar\n",
    "Y_predict = clf.predict(X_test)\n",
    "\n",
    "#Obtenemos la tasa de acierto de lo predicho respecto a lo esperado\n",
    "score = clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de aciertos obtenida con hold out utilizando regresión logística multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.49511213341000576\n"
     ]
    }
   ],
   "source": [
    "print(\"Tasa de aciertos =\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión obtenida con hold out utilizando regresión logística multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      " [[2804    0    0    0    6   45    0    0    0    0    2    0]\n",
      " [   3    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  62    0    0    0    0    7    0    0    0    0    0    0]\n",
      " [ 226    0    0    0    0    8    0    1    0    0    0    0]\n",
      " [ 711    0    0    0    0   19    0    0    0    0    0    0]\n",
      " [1290    0    0    0    4    7    0    3    4    0    0    0]\n",
      " [ 293    0    0    0    0    0    0    1    0    0    4    0]\n",
      " [ 305    0    0    0    0   35    0    0    6    0    0    0]\n",
      " [  47    0    0    0    1    6    0    7  490    0    3    0]\n",
      " [  30    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 198    0    0    0    3    4    0    0    0    0  143    0]\n",
      " [ 120    0    0    0    2    0    0    0   25    0   31    0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMatriz de Confusión:\\n\", confusion_matrix(Y_test, Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation 10 particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número de particiones en que queremos dividir el dataset\n",
    "subsamples = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=subsamples, random_state=None, shuffle=False)\n",
    "#Variable para calcular la tasa de acierto media\n",
    "score = 0\n",
    "#Asignamos las particiones de train y test un total de 10 veces\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    #Dividimos en train y test según los índices que nos marca el iterador\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    #Creamos el clasificador\n",
    "    clf = LogisticRegression(n_jobs=-1)\n",
    "    \n",
    "    #Ajustamos el clasificador con los datos de entrenamiento\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    #Sumamos todos los scores\n",
    "    score = score + clf.score(X_test, Y_test)\n",
    "\n",
    "#Para a continuación obtener el score medio\n",
    "score = score/subsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de aciertos obtenida con XV 10 particiones utilizando regresión logística multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.49753192961404225\n"
     ]
    }
   ],
   "source": [
    "print(\"Tasa de aciertos =\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos resultados son prácticamente idénticos, no notamos una mejora significativa al variar los conjuntos de entrenamiento y test. Respecto a los resultados obtenidos con la regresión lineal múltiple tampoco cambian mucho además estos eran menos costosos computacionalmente, la validación cruzada con regresión logística puede ser paralelizada aunque en nuestro caso no sea así y notemos ese aumento del coste computacional que mencionamos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
